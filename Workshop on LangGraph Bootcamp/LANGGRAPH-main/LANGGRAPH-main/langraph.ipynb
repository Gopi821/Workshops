{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langgraph langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b67019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain_groq langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee695f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key='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'\n",
    "langsmith='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2724af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78247cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000243CE4A64E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000243CE3F3B60>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key, model_name=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ef0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871f8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "  messages:Annotated[list,add_messages]\n",
    "\n",
    "graph_builder=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b282924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x243ce4edf40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "961ef917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State):\n",
    "  return {\"messages\":llm.invoke(state['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1912277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x243ce4edf40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"chatbot\",chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e05459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x243ce4edf40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6863791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x243ce4edf40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START,\"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d371097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c662593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d89704b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([{'messages': AIMessage(content=\"##  Databricks: The Unified Data and AI Platform\\n\\nDatabricks is a leading platform for **unified data and AI**, offering a collaborative, scalable, and secure environment for data engineering, data science, and machine learning. \\n\\n**Here's a breakdown:**\\n\\n**Core Features:**\\n\\n* **Lakehouse Architecture:** Combines the best of data lakes and data warehouses, enabling efficient storage, processing, and analysis of structured, semi-structured, and unstructured data.\\n* **Spark-Based Engine:** Leverages Apache Spark, a powerful open-source engine for distributed data processing, providing high performance and scalability.\\n* **Data Engineering Tools:** Includes tools for data ingestion, transformation, and management, enabling efficient data pipelines and workflows.\\n* **Data Science and Machine Learning:** Offers a suite of tools and libraries for data exploration, model development, and deployment, empowering data scientists to build and deploy AI applications.\\n* **Collaboration and Governance:** Facilitates team collaboration with shared workspaces, version control, and access controls, while ensuring data governance and security.\\n\\n**Benefits:**\\n\\n* **Unified Platform:** Consolidates data and AI workloads onto a single platform, simplifying operations and reducing complexity.\\n* **Scalability and Performance:** Handles massive datasets and complex computations with high speed and efficiency.\\n* **Open and Extensible:** Integrates with various tools and technologies, allowing customization and flexibility.\\n* **Collaboration and Innovation:** Fosters collaboration among data engineers, data scientists, and business users, accelerating innovation.\\n* **Security and Compliance:** Provides robust security features and compliance certifications, protecting sensitive data.\\n\\n**Use Cases:**\\n\\n* **Data Analytics:** Gain insights from large datasets for business intelligence, reporting, and decision-making.\\n* **Machine Learning:** Build and deploy predictive models for various applications, such as fraud detection, customer segmentation, and personalized recommendations.\\n* **Data Engineering:** Create and manage data pipelines for data ingestion, transformation, and loading.\\n* **Scientific Research:** Analyze complex scientific data for research and discovery.\\n* **Financial Services:** Analyze financial data for risk management, fraud prevention, and investment strategies.\\n\\n**Overall, Databricks empowers organizations to harness the power of data and AI to drive innovation, improve efficiency, and achieve their business goals.**\\n\\n\\nLet me know if you have any more specific questions about Databricks.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 488, 'prompt_tokens': 13, 'total_tokens': 501, 'completion_time': 0.887272727, 'prompt_time': 0.001914916, 'queue_time': 0.246146154, 'total_time': 0.889187643}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f44e5bc6-5191-45cf-a9ba-852729e0786f-0', usage_metadata={'input_tokens': 13, 'output_tokens': 488, 'total_tokens': 501})}])\n",
      "content=\"##  Databricks: The Unified Data and AI Platform\\n\\nDatabricks is a leading platform for **unified data and AI**, offering a collaborative, scalable, and secure environment for data engineering, data science, and machine learning. \\n\\n**Here's a breakdown:**\\n\\n**Core Features:**\\n\\n* **Lakehouse Architecture:** Combines the best of data lakes and data warehouses, enabling efficient storage, processing, and analysis of structured, semi-structured, and unstructured data.\\n* **Spark-Based Engine:** Leverages Apache Spark, a powerful open-source engine for distributed data processing, providing high performance and scalability.\\n* **Data Engineering Tools:** Includes tools for data ingestion, transformation, and management, enabling efficient data pipelines and workflows.\\n* **Data Science and Machine Learning:** Offers a suite of tools and libraries for data exploration, model development, and deployment, empowering data scientists to build and deploy AI applications.\\n* **Collaboration and Governance:** Facilitates team collaboration with shared workspaces, version control, and access controls, while ensuring data governance and security.\\n\\n**Benefits:**\\n\\n* **Unified Platform:** Consolidates data and AI workloads onto a single platform, simplifying operations and reducing complexity.\\n* **Scalability and Performance:** Handles massive datasets and complex computations with high speed and efficiency.\\n* **Open and Extensible:** Integrates with various tools and technologies, allowing customization and flexibility.\\n* **Collaboration and Innovation:** Fosters collaboration among data engineers, data scientists, and business users, accelerating innovation.\\n* **Security and Compliance:** Provides robust security features and compliance certifications, protecting sensitive data.\\n\\n**Use Cases:**\\n\\n* **Data Analytics:** Gain insights from large datasets for business intelligence, reporting, and decision-making.\\n* **Machine Learning:** Build and deploy predictive models for various applications, such as fraud detection, customer segmentation, and personalized recommendations.\\n* **Data Engineering:** Create and manage data pipelines for data ingestion, transformation, and loading.\\n* **Scientific Research:** Analyze complex scientific data for research and discovery.\\n* **Financial Services:** Analyze financial data for risk management, fraud prevention, and investment strategies.\\n\\n**Overall, Databricks empowers organizations to harness the power of data and AI to drive innovation, improve efficiency, and achieve their business goals.**\\n\\n\\nLet me know if you have any more specific questions about Databricks.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 488, 'prompt_tokens': 13, 'total_tokens': 501, 'completion_time': 0.887272727, 'prompt_time': 0.001914916, 'queue_time': 0.246146154, 'total_time': 0.889187643}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--f44e5bc6-5191-45cf-a9ba-852729e0786f-0' usage_metadata={'input_tokens': 13, 'output_tokens': 488, 'total_tokens': 501}\n",
      "Assistant: ##  Databricks: The Unified Data and AI Platform\n",
      "\n",
      "Databricks is a leading platform for **unified data and AI**, offering a collaborative, scalable, and secure environment for data engineering, data science, and machine learning. \n",
      "\n",
      "**Here's a breakdown:**\n",
      "\n",
      "**Core Features:**\n",
      "\n",
      "* **Lakehouse Architecture:** Combines the best of data lakes and data warehouses, enabling efficient storage, processing, and analysis of structured, semi-structured, and unstructured data.\n",
      "* **Spark-Based Engine:** Leverages Apache Spark, a powerful open-source engine for distributed data processing, providing high performance and scalability.\n",
      "* **Data Engineering Tools:** Includes tools for data ingestion, transformation, and management, enabling efficient data pipelines and workflows.\n",
      "* **Data Science and Machine Learning:** Offers a suite of tools and libraries for data exploration, model development, and deployment, empowering data scientists to build and deploy AI applications.\n",
      "* **Collaboration and Governance:** Facilitates team collaboration with shared workspaces, version control, and access controls, while ensuring data governance and security.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Unified Platform:** Consolidates data and AI workloads onto a single platform, simplifying operations and reducing complexity.\n",
      "* **Scalability and Performance:** Handles massive datasets and complex computations with high speed and efficiency.\n",
      "* **Open and Extensible:** Integrates with various tools and technologies, allowing customization and flexibility.\n",
      "* **Collaboration and Innovation:** Fosters collaboration among data engineers, data scientists, and business users, accelerating innovation.\n",
      "* **Security and Compliance:** Provides robust security features and compliance certifications, protecting sensitive data.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "* **Data Analytics:** Gain insights from large datasets for business intelligence, reporting, and decision-making.\n",
      "* **Machine Learning:** Build and deploy predictive models for various applications, such as fraud detection, customer segmentation, and personalized recommendations.\n",
      "* **Data Engineering:** Create and manage data pipelines for data ingestion, transformation, and loading.\n",
      "* **Scientific Research:** Analyze complex scientific data for research and discovery.\n",
      "* **Financial Services:** Analyze financial data for risk management, fraud prevention, and investment strategies.\n",
      "\n",
      "**Overall, Databricks empowers organizations to harness the power of data and AI to drive innovation, improve efficiency, and achieve their business goals.**\n",
      "\n",
      "\n",
      "Let me know if you have any more specific questions about Databricks.\n",
      "\n",
      "dict_values([{'messages': AIMessage(content='Please provide me with some context or a question so I can assist you. \\n\\nFor example, you could ask:\\n\\n* **\"What is the capital of France?\"**\\n* **\"Can you write a short story about a robot who learns to feel emotions?\"**\\n* **\"What are some tips for learning a new language?\"**\\n\\n\\nI\\'m ready to help with whatever you need! ðŸ˜Š\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 11, 'total_tokens': 99, 'completion_time': 0.16, 'prompt_time': 0.001928076, 'queue_time': 0.244087993, 'total_time': 0.161928076}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--e176083b-5272-4d0a-be40-91c6cc2667ec-0', usage_metadata={'input_tokens': 11, 'output_tokens': 88, 'total_tokens': 99})}])\n",
      "content='Please provide me with some context or a question so I can assist you. \\n\\nFor example, you could ask:\\n\\n* **\"What is the capital of France?\"**\\n* **\"Can you write a short story about a robot who learns to feel emotions?\"**\\n* **\"What are some tips for learning a new language?\"**\\n\\n\\nI\\'m ready to help with whatever you need! ðŸ˜Š\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 11, 'total_tokens': 99, 'completion_time': 0.16, 'prompt_time': 0.001928076, 'queue_time': 0.244087993, 'total_time': 0.161928076}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--e176083b-5272-4d0a-be40-91c6cc2667ec-0' usage_metadata={'input_tokens': 11, 'output_tokens': 88, 'total_tokens': 99}\n",
      "Assistant: Please provide me with some context or a question so I can assist you. \n",
      "\n",
      "For example, you could ask:\n",
      "\n",
      "* **\"What is the capital of France?\"**\n",
      "* **\"Can you write a short story about a robot who learns to feel emotions?\"**\n",
      "* **\"What are some tips for learning a new language?\"**\n",
      "\n",
      "\n",
      "I'm ready to help with whatever you need! ðŸ˜Š\n",
      "\n",
      "\n",
      "dict_values([{'messages': AIMessage(content='It seems you\\'re interested in \"langgraph\"!  \\n\\nLet me tell you, that\\'s an exciting topic!  Langgraph is a fascinating field at the intersection of language modeling and graph theory. \\n\\n**Here\\'s a breakdown of what you might be looking for:**\\n\\n* **What is Langgraph?**\\n\\nLanggraph refers to the use of graph-based representations and algorithms to analyze and understand natural language. \\n\\nThink of it like this:\\n\\n* **Words as Nodes:** Each word in a sentence or document becomes a \"node\" in a graph.\\n* **Relationships as Edges:** The connections between words (like subject-verb, noun-adjective, or concepts related to each other) are represented as \"edges\" connecting these nodes.\\n\\n* **Why use Graphs?**\\n\\nGraphs are incredibly powerful for capturing the complex relationships within language.  They allow us to:\\n\\n    * **Understand Sentence Structure:**  See how words are connected to form meaningful phrases and clauses.\\n    * **Identify Relationships:** Discover connections between concepts, even if they aren\\'t explicitly stated in the text.\\n    * **Represent Knowledge:** Build knowledge graphs that capture facts and relationships about the world.\\n\\n* **Applications of Langgraph:**\\n\\nLanggraph has a wide range of applications, including:\\n\\n    * **Question Answering:**  Finding answers to questions by traversing relationships in a knowledge graph.\\n    * **Text Summarization:** Identifying key concepts and relationships to generate concise summaries.\\n    * **Sentiment Analysis:** Understanding the emotional tone of text by analyzing relationships between words.\\n    * **Machine Translation:**  Leveraging semantic relationships to improve the accuracy of translations.\\n\\n* **Tools and Libraries:**\\n\\nThere are several tools and libraries that make working with langgraph easier:\\n\\n    * **NetworkX:** A popular Python library for creating, manipulating, and analyzing graphs.\\n    * **SpaCy:** A powerful natural language processing library that includes tools for graph-based analysis.\\n    * **Hugging Face Transformers:**  A library with pre-trained language models that can be adapted for langgraph tasks.\\n\\n\\n\\nLet me know if you have any more specific questions about langgraph! I\\'m happy to delve deeper into particular aspects or applications.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 466, 'prompt_tokens': 11, 'total_tokens': 477, 'completion_time': 0.847272727, 'prompt_time': 0.001913617, 'queue_time': 0.24637424, 'total_time': 0.849186344}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a12a523-a766-492c-89e6-e4f45ac7bfcd-0', usage_metadata={'input_tokens': 11, 'output_tokens': 466, 'total_tokens': 477})}])\n",
      "content='It seems you\\'re interested in \"langgraph\"!  \\n\\nLet me tell you, that\\'s an exciting topic!  Langgraph is a fascinating field at the intersection of language modeling and graph theory. \\n\\n**Here\\'s a breakdown of what you might be looking for:**\\n\\n* **What is Langgraph?**\\n\\nLanggraph refers to the use of graph-based representations and algorithms to analyze and understand natural language. \\n\\nThink of it like this:\\n\\n* **Words as Nodes:** Each word in a sentence or document becomes a \"node\" in a graph.\\n* **Relationships as Edges:** The connections between words (like subject-verb, noun-adjective, or concepts related to each other) are represented as \"edges\" connecting these nodes.\\n\\n* **Why use Graphs?**\\n\\nGraphs are incredibly powerful for capturing the complex relationships within language.  They allow us to:\\n\\n    * **Understand Sentence Structure:**  See how words are connected to form meaningful phrases and clauses.\\n    * **Identify Relationships:** Discover connections between concepts, even if they aren\\'t explicitly stated in the text.\\n    * **Represent Knowledge:** Build knowledge graphs that capture facts and relationships about the world.\\n\\n* **Applications of Langgraph:**\\n\\nLanggraph has a wide range of applications, including:\\n\\n    * **Question Answering:**  Finding answers to questions by traversing relationships in a knowledge graph.\\n    * **Text Summarization:** Identifying key concepts and relationships to generate concise summaries.\\n    * **Sentiment Analysis:** Understanding the emotional tone of text by analyzing relationships between words.\\n    * **Machine Translation:**  Leveraging semantic relationships to improve the accuracy of translations.\\n\\n* **Tools and Libraries:**\\n\\nThere are several tools and libraries that make working with langgraph easier:\\n\\n    * **NetworkX:** A popular Python library for creating, manipulating, and analyzing graphs.\\n    * **SpaCy:** A powerful natural language processing library that includes tools for graph-based analysis.\\n    * **Hugging Face Transformers:**  A library with pre-trained language models that can be adapted for langgraph tasks.\\n\\n\\n\\nLet me know if you have any more specific questions about langgraph! I\\'m happy to delve deeper into particular aspects or applications.\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 466, 'prompt_tokens': 11, 'total_tokens': 477, 'completion_time': 0.847272727, 'prompt_time': 0.001913617, 'queue_time': 0.24637424, 'total_time': 0.849186344}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--1a12a523-a766-492c-89e6-e4f45ac7bfcd-0' usage_metadata={'input_tokens': 11, 'output_tokens': 466, 'total_tokens': 477}\n",
      "Assistant: It seems you're interested in \"langgraph\"!  \n",
      "\n",
      "Let me tell you, that's an exciting topic!  Langgraph is a fascinating field at the intersection of language modeling and graph theory. \n",
      "\n",
      "**Here's a breakdown of what you might be looking for:**\n",
      "\n",
      "* **What is Langgraph?**\n",
      "\n",
      "Langgraph refers to the use of graph-based representations and algorithms to analyze and understand natural language. \n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "* **Words as Nodes:** Each word in a sentence or document becomes a \"node\" in a graph.\n",
      "* **Relationships as Edges:** The connections between words (like subject-verb, noun-adjective, or concepts related to each other) are represented as \"edges\" connecting these nodes.\n",
      "\n",
      "* **Why use Graphs?**\n",
      "\n",
      "Graphs are incredibly powerful for capturing the complex relationships within language.  They allow us to:\n",
      "\n",
      "    * **Understand Sentence Structure:**  See how words are connected to form meaningful phrases and clauses.\n",
      "    * **Identify Relationships:** Discover connections between concepts, even if they aren't explicitly stated in the text.\n",
      "    * **Represent Knowledge:** Build knowledge graphs that capture facts and relationships about the world.\n",
      "\n",
      "* **Applications of Langgraph:**\n",
      "\n",
      "Langgraph has a wide range of applications, including:\n",
      "\n",
      "    * **Question Answering:**  Finding answers to questions by traversing relationships in a knowledge graph.\n",
      "    * **Text Summarization:** Identifying key concepts and relationships to generate concise summaries.\n",
      "    * **Sentiment Analysis:** Understanding the emotional tone of text by analyzing relationships between words.\n",
      "    * **Machine Translation:**  Leveraging semantic relationships to improve the accuracy of translations.\n",
      "\n",
      "* **Tools and Libraries:**\n",
      "\n",
      "There are several tools and libraries that make working with langgraph easier:\n",
      "\n",
      "    * **NetworkX:** A popular Python library for creating, manipulating, and analyzing graphs.\n",
      "    * **SpaCy:** A powerful natural language processing library that includes tools for graph-based analysis.\n",
      "    * **Hugging Face Transformers:**  A library with pre-trained language models that can be adapted for langgraph tasks.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any more specific questions about langgraph! I'm happy to delve deeper into particular aspects or applications.\n",
      "\n",
      "dict_values([{'messages': AIMessage(content=\"Please provide me with a question or prompt so I can assist you! I'm ready for anything from creative writing to answering factual questions. ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 11, 'total_tokens': 44, 'completion_time': 0.06, 'prompt_time': 0.001936906, 'queue_time': 0.24223291400000002, 'total_time': 0.061936906}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--91d112f5-21a6-45cb-9807-4d36306dacb2-0', usage_metadata={'input_tokens': 11, 'output_tokens': 33, 'total_tokens': 44})}])\n",
      "content=\"Please provide me with a question or prompt so I can assist you! I'm ready for anything from creative writing to answering factual questions. ðŸ˜Š \\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 11, 'total_tokens': 44, 'completion_time': 0.06, 'prompt_time': 0.001936906, 'queue_time': 0.24223291400000002, 'total_time': 0.061936906}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--91d112f5-21a6-45cb-9807-4d36306dacb2-0' usage_metadata={'input_tokens': 11, 'output_tokens': 33, 'total_tokens': 44}\n",
      "Assistant: Please provide me with a question or prompt so I can assist you! I'm ready for anything from creative writing to answering factual questions. ðŸ˜Š \n",
      "\n",
      "dict_values([{'messages': AIMessage(content='Please provide me with a question or topic you\\'d like to discuss. I\\'m ready to help! \\n\\nFor example, you could ask me:\\n\\n* **A question about a specific topic:** \"What is the capital of France?\"\\n* **A creative writing prompt:** \"Write a short story about a robot who learns to feel emotions.\"\\n* **A request for information:** \"Tell me about the history of the internet.\"\\n* **A task:** \"Summarize the main points of this article.\"\\n\\nI\\'m excited to see what you have in mind! ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 11, 'total_tokens': 135, 'completion_time': 0.225454545, 'prompt_time': 0.001979027, 'queue_time': 0.244713426, 'total_time': 0.227433572}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--419ba096-812f-4671-b1e8-80da3404ea22-0', usage_metadata={'input_tokens': 11, 'output_tokens': 124, 'total_tokens': 135})}])\n",
      "content='Please provide me with a question or topic you\\'d like to discuss. I\\'m ready to help! \\n\\nFor example, you could ask me:\\n\\n* **A question about a specific topic:** \"What is the capital of France?\"\\n* **A creative writing prompt:** \"Write a short story about a robot who learns to feel emotions.\"\\n* **A request for information:** \"Tell me about the history of the internet.\"\\n* **A task:** \"Summarize the main points of this article.\"\\n\\nI\\'m excited to see what you have in mind! ðŸ˜Š \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 11, 'total_tokens': 135, 'completion_time': 0.225454545, 'prompt_time': 0.001979027, 'queue_time': 0.244713426, 'total_time': 0.227433572}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--419ba096-812f-4671-b1e8-80da3404ea22-0' usage_metadata={'input_tokens': 11, 'output_tokens': 124, 'total_tokens': 135}\n",
      "Assistant: Please provide me with a question or topic you'd like to discuss. I'm ready to help! \n",
      "\n",
      "For example, you could ask me:\n",
      "\n",
      "* **A question about a specific topic:** \"What is the capital of France?\"\n",
      "* **A creative writing prompt:** \"Write a short story about a robot who learns to feel emotions.\"\n",
      "* **A request for information:** \"Tell me about the history of the internet.\"\n",
      "* **A task:** \"Summarize the main points of this article.\"\n",
      "\n",
      "I'm excited to see what you have in mind! ðŸ˜Š \n",
      "\n",
      "dict_values([{'messages': AIMessage(content=\"Please provide me with a prompt or question so I can assist you. For example, you could ask me:\\n\\n* To write a story\\n* To translate text\\n* To summarize an article\\n* To answer a factual question\\n* To generate creative content\\n\\nI'm ready to help! ðŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 11, 'total_tokens': 76, 'completion_time': 0.118181818, 'prompt_time': 0.001918967, 'queue_time': 0.24431176300000002, 'total_time': 0.120100785}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f89623c6-2169-4ba0-a656-e09902643f03-0', usage_metadata={'input_tokens': 11, 'output_tokens': 65, 'total_tokens': 76})}])\n",
      "content=\"Please provide me with a prompt or question so I can assist you. For example, you could ask me:\\n\\n* To write a story\\n* To translate text\\n* To summarize an article\\n* To answer a factual question\\n* To generate creative content\\n\\nI'm ready to help! ðŸ˜Š \\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 11, 'total_tokens': 76, 'completion_time': 0.118181818, 'prompt_time': 0.001918967, 'queue_time': 0.24431176300000002, 'total_time': 0.120100785}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--f89623c6-2169-4ba0-a656-e09902643f03-0' usage_metadata={'input_tokens': 11, 'output_tokens': 65, 'total_tokens': 76}\n",
      "Assistant: Please provide me with a prompt or question so I can assist you. For example, you could ask me:\n",
      "\n",
      "* To write a story\n",
      "* To translate text\n",
      "* To summarize an article\n",
      "* To answer a factual question\n",
      "* To generate creative content\n",
      "\n",
      "I'm ready to help! ðŸ˜Š \n",
      "\n",
      "dict_values([{'messages': AIMessage(content='Please provide me with some context or a question so I can assist you. For example, you could ask:\\n\\n* **\"What is the weather like in London?\"**\\n* **\"Can you write a short story about a robot?\"**\\n* **\"What are the main ingredients in a chocolate chip cookie?\"**\\n\\n\\nI\\'m ready to help with a wide range of tasks, so feel free to ask!\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 11, 'total_tokens': 101, 'completion_time': 0.163636364, 'prompt_time': 0.001909637, 'queue_time': 0.24734287200000002, 'total_time': 0.165546001}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--80f75803-a4cd-49ba-9a71-a18eb0c0d757-0', usage_metadata={'input_tokens': 11, 'output_tokens': 90, 'total_tokens': 101})}])\n",
      "content='Please provide me with some context or a question so I can assist you. For example, you could ask:\\n\\n* **\"What is the weather like in London?\"**\\n* **\"Can you write a short story about a robot?\"**\\n* **\"What are the main ingredients in a chocolate chip cookie?\"**\\n\\n\\nI\\'m ready to help with a wide range of tasks, so feel free to ask!\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 11, 'total_tokens': 101, 'completion_time': 0.163636364, 'prompt_time': 0.001909637, 'queue_time': 0.24734287200000002, 'total_time': 0.165546001}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--80f75803-a4cd-49ba-9a71-a18eb0c0d757-0' usage_metadata={'input_tokens': 11, 'output_tokens': 90, 'total_tokens': 101}\n",
      "Assistant: Please provide me with some context or a question so I can assist you. For example, you could ask:\n",
      "\n",
      "* **\"What is the weather like in London?\"**\n",
      "* **\"Can you write a short story about a robot?\"**\n",
      "* **\"What are the main ingredients in a chocolate chip cookie?\"**\n",
      "\n",
      "\n",
      "I'm ready to help with a wide range of tasks, so feel free to ask!\n",
      "\n",
      "\n",
      "dict_values([{'messages': AIMessage(content=\"Please provide me with a prompt or question so I can assist you! \\n\\nFor example, you could ask me:\\n\\n* To write a poem about a specific topic\\n* To translate a phrase into another language\\n* To summarize a news article\\n* To generate ideas for a creative project\\n* To answer a factual question\\n\\nI'm ready to help! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 11, 'total_tokens': 89, 'completion_time': 0.141818182, 'prompt_time': 0.002681815, 'queue_time': 0.249599524, 'total_time': 0.144499997}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ee39c9d8-bf40-49cf-b0b5-93dfb965d879-0', usage_metadata={'input_tokens': 11, 'output_tokens': 78, 'total_tokens': 89})}])\n",
      "content=\"Please provide me with a prompt or question so I can assist you! \\n\\nFor example, you could ask me:\\n\\n* To write a poem about a specific topic\\n* To translate a phrase into another language\\n* To summarize a news article\\n* To generate ideas for a creative project\\n* To answer a factual question\\n\\nI'm ready to help! ðŸ˜Š\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 11, 'total_tokens': 89, 'completion_time': 0.141818182, 'prompt_time': 0.002681815, 'queue_time': 0.249599524, 'total_time': 0.144499997}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--ee39c9d8-bf40-49cf-b0b5-93dfb965d879-0' usage_metadata={'input_tokens': 11, 'output_tokens': 78, 'total_tokens': 89}\n",
      "Assistant: Please provide me with a prompt or question so I can assist you! \n",
      "\n",
      "For example, you could ask me:\n",
      "\n",
      "* To write a poem about a specific topic\n",
      "* To translate a phrase into another language\n",
      "* To summarize a news article\n",
      "* To generate ideas for a creative project\n",
      "* To answer a factual question\n",
      "\n",
      "I'm ready to help! ðŸ˜Š\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m   user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGood Bye\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  user_input=input(\"User: \")\n",
    "  if user_input.lower() in [\"quit\",\"q\"]:\n",
    "    print(\"Good Bye\")\n",
    "    break\n",
    "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
    "    print(event.values())\n",
    "    for value in event.values():\n",
    "      print(value['messages'])\n",
    "      print(\"Assistant:\",value[\"messages\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc88bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fe0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
